<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 2 Validação Cruzada | Machine Learning Posts</title>
  <meta name="description" content="Book">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 2 Validação Cruzada | Machine Learning Posts />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Book" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Validação Cruzada | Machine Learning Posts />
  
  <meta name="twitter:description" content="Book" />
  



<meta name="date" content="2019-01-04">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="valid.html"><a href="valid.html"><i class="fa fa-check"></i><b>2</b> Validação Cruzada</a><ul>
<li class="chapter" data-level="2.1" data-path="valid.html"><a href="valid.html#definicao"><i class="fa fa-check"></i><b>2.1</b> Definição</a><ul>
<li class="chapter" data-level="2.1.1" data-path="valid.html"><a href="valid.html#holdout"><i class="fa fa-check"></i><b>2.1.1</b> Holdout</a></li>
<li class="chapter" data-level="2.1.2" data-path="valid.html"><a href="valid.html#k-fold"><i class="fa fa-check"></i><b>2.1.2</b> K-fold</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="valid.html"><a href="valid.html#exemplo-de-utilizacao"><i class="fa fa-check"></i><b>2.2</b> Exemplo de Utilização</a><ul>
<li class="chapter" data-level="2.2.1" data-path="valid.html"><a href="valid.html#validacao-cruzada-para-encontrar-o-numero-de-graus-de-liberdade"><i class="fa fa-check"></i><b>2.2.1</b> Validação cruzada para encontrar o número de graus de liberdade</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning Posts</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="valid" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Validação Cruzada</h1>
<div id="definicao" class="section level2">
<h2><span class="header-section-number">2.1</span> Definição</h2>
<p>Na falta de uma grande base de dados de teste, utilizada para
estimar a taxa de erro do algoritmo, algumas técnicas podem ser
aplicadas para quantificar esta taxa usando os próprios dados
disponíveis para treino. Uma destas técnicas é a validação cruzada.
Ela consiste em calcular a taxa de erro em um certo subconjunto dos
dados de treino, separado previamente. Ou seja, estes dados não participam
do aprendizado do modelo, e ajudam a ter uma ideia de como ele
se comporta ao receber observações não familiares..</p>
<div id="holdout" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Holdout</h3>
<p>A técnica conhecida como <em>holdout</em> consiste na divisão dos dados
em treino e validação, dada alguma proporção pré-definida, como
<em>80-20</em> (80% dos dados para treino e 20% para validação) ou <em>70-30</em>.
O algoritmo aprende com o subconjunto de treino e o restante dos dados
é usado para predição. O erro proveniente dos dados de validação
fornece uma estimativa do erro de teste, que é normalmente quantificado
pelo <strong>erro quadrático médio</strong> para variáveis contínuas e pela <strong>taxa
de classificação incorreta</strong> no caso de variáveis discretas.</p>
</div>
<div id="k-fold" class="section level3">
<h3><span class="header-section-number">2.1.2</span> K-fold</h3>
<p>A técnica de validação cruzada chamada de “k-fold” (‘k dobras’) é
quando faz-se a divisão dos dados de treino em <em>k</em> partes iguais,
reservando <em>k-1</em> partes para o treino e <em>1</em> parte para o cálculo da
medida de erro. Este processo é feito para cada uma das <em>k</em> partes,
isto é, todas as partes passam pelo estado de “treino” e “validação”,
e os <em>k</em> resultados obtidos para o erro são combinados através de:
<span class="math display">\[ CV_{k} = \sum_{k = 1}^{K} \frac{n_k}{n} EQM_k,\]</span>
Com <span class="math inline">\(EQM_k = \sum_{i \in C_k} \frac{(y_i - \hat y_i)^2}{n_k}\)</span>, para
o caso de variáveis contínuas e:</p>
<p><span class="math display">\[ CV_{k} = \sum_{k = 1}^{K} \frac{n_k}{n} Err_k,\]</span></p>
<p>Onde <span class="math inline">\(Err_k = \sum_{i \in C_k} \frac{(y_i \neq \hat y_i)}{n_k}\)</span>, para
quando a variável é discreta, representando a taxa de classificação
incorreta.</p>
<ul>
<li>O caso específico de <em>n-fold</em> é conhecido como Leave-One-Out. Este
nome vem de que em cada etapa do processo, apenas uma observação é
deixada de fora do treino.</li>
</ul>
</div>
</div>
<div id="exemplo-de-utilizacao" class="section level2">
<h2><span class="header-section-number">2.2</span> Exemplo de Utilização</h2>
<div id="validacao-cruzada-para-encontrar-o-numero-de-graus-de-liberdade" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Validação cruzada para encontrar o número de graus de liberdade</h3>
<p>ótimo em suavização por splines.</p>
<p>Suavizadores por spline são uma extensão de regressão
polinomial por partes, que consiste no ajuste de polinômios em
diferentes regiões de uma variável explicativa <span class="math inline">\(\mathbf{x}\)</span>. Por
exemplo, podemos ter um ponto de quebra em <span class="math inline">\(c\)</span>, de form que</p>
<p><span class="math display">\[
y_i = \begin{cases}
\beta_{01} + \beta_{11} x_i + \beta_{21} x_{i}^{2} +
\beta_{31} x_{i}^{3} &amp;\text{if $x_i &lt; c$}\\
\beta_{02} + \beta_{12} x_i + \beta_{22} x_{i}^{2} +
\beta_{32} x_{i}^{3}  &amp;\text{if $x_i \geq c$},
\end{cases}
\]</span></p>
<p>onde <span class="math inline">\(y_i\)</span> é o vetor da resposta e os <span class="math inline">\(\beta_{md}\)</span> são os coeficientes
dos ajustes “antes” e “depois” do ponto <span class="math inline">\(c\)</span> da variável <span class="math inline">\(\mathbf{x}\)</span>.
Esta representação é a de um polinômio cúbico, com <span class="math inline">\(d = 3\)</span>.</p>
<p>A quebra no ponto <span class="math inline">\(c\)</span> torna os polinômios discontínuos. Ao adicionarmos
a restrição de que a curva deve ser contínua, chegamos na
suavização por splines. Esta restrição é feita em ambas primeira e
segunda derivadas das funções, tornando-as muito suaves.</p>
<p>As novas restrições “libertam” um <strong>grau de liberdade</strong> cada. Eles
podem ser entendidos como a quantidade de coeficientes estimados. No
caso dos splines cúbicos com K pontos de quebra, 4 + K coeficientes
são estimados.</p>
<p>Splines podem ser reprentados com funções base, por exemplo</p>
<p><span class="math display">\[ y_i = \beta_0 + \beta_1 b_1(x_i) + \beta_2 b_2(x_{i}) +
\dots + \beta_{K+3} b_{K+3}(x_{i}) + \epsilon_i.  \]</span></p>
<p>aonde <span class="math inline">\(b_1, \dots, b_{K+3}\)</span> são as funções. A forma mais comum de
representar um spline cúbico é começar com uma função base
de um polinômio cúbico e adicionar uma função truncada por ponto de
quebra. Esta função, por sua vez, pode ser definida como</p>
<p><span class="math display">\[
h(x, \epsilon) = (x - \epsilon)_{+}^{3} = 
\begin{cases}
(x - \epsilon)^{3} &amp;\text{if $x &gt; \epsilon$}\\
0 &amp;\text{otherwise}
\end{cases}
\]</span></p>
<p>aonde <span class="math inline">\(\epsilon\)</span> é o ponto de quebra. A adição do termo truncado
leva à discontinuidade apenas a partir da terceira derivada da função,
levando às restrições desejadas: a função seraaá contínua, com
primeira e segunda derivadas contínuas em cada ponto de quebra.</p>
<p>Estamos usando os splines cúbicos pois podemos verificar como a função se
comporta ao variarmos os graus de liberdade (ou pontos de quebra,
uma vez que GL = 4 + pontos de quebra). A ideia é usar validação cruzada
para encontrar o número de graus de liberdade ideal para o problema.</p>
<p>Considere agora os seguintes dados: uma medida de energia e uma de dançabilidade
extraídas com a <a href="https://r-music.rbind.io/posts/2018-10-01-rspotify/">API do Spotify</a>
para as músicas da playlist chamada “New Music Friday” de 04 de janeiro de
2019. A relação entre estas duas variáveis vai ser modelada a seguir
com um spline suavizador:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(splines)
<span class="kw">library</span>(ggpomological)
<span class="kw">library</span>(patchwork)

<span class="co"># Carregando dados e construindo gráficos</span>
df &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;data/playlist_songs.txt&quot;</span>)

p1 &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(energy, danceability)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">colour =</span> <span class="st">&#39;#f5c04a&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">colour =</span> <span class="st">&#39;#2b323f&#39;</span>,
              <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>,
              <span class="dt">formula=</span>y <span class="op">~</span><span class="st"> </span><span class="kw">ns</span>(x, <span class="dv">5</span>))<span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Graus de Liberdade = 5&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()

p2 &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(energy, danceability)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">colour =</span> <span class="st">&#39;#f5c04a&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">colour =</span> <span class="st">&#39;#2b323f&#39;</span>,
              <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>,
              <span class="dt">formula=</span>y <span class="op">~</span><span class="st"> </span><span class="kw">ns</span>(x, <span class="dv">15</span>))<span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Graus de Liberdade = 15&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Dançabilidade&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()

p3 &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(energy, danceability)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">colour =</span> <span class="st">&#39;#f5c04a&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">colour =</span> <span class="st">&#39;#2b323f&#39;</span>,
              <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>,
              <span class="dt">formula=</span>y <span class="op">~</span><span class="st"> </span><span class="kw">ns</span>(x,<span class="dv">25</span>))<span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Graus de Liberdade = 25&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;Energia&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()

p1 <span class="op">+</span><span class="st"> </span>p2 <span class="op">+</span><span class="st"> </span>p3 <span class="op">+</span><span class="st"> </span><span class="kw">plot_layout</span>(<span class="dt">nrow =</span> <span class="dv">3</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="bookdown_files/figure-html/unnamed-chunk-2-1.svg" alt="Exemplos da variação da quantidade de graus de liberdade do suavizador." width="576" />
<p class="caption">
Figure 2.1: Exemplos da variação da quantidade de graus de liberdade do suavizador.
</p>
</div>
<p>Claramente, quanto mais graus de liberdade, mais a curva corre atrás dos
dados. Se queremos um bom ajuste, é preciso avaliar o quanto podemos
deixar que a curva se ajuste aos dados sem deixar que ela perca a generalidade.
Isto é: é preciso verificar até que ponto a curva ajustada é boa também para
prever dados que não foram usados no treinamento. O código a seguir mostra
como testar diferentes graus de liberdade usando validação cruzada, ao
separar a base em um conjunto para o treinamento do modelo em e um para
a validação. Aqui, escolhemos criar 5 diferentes pares de conjuntos, usando
usando o que definimos antes como <strong>k-fold</strong>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Criando uma função que recebe o fold que vai ser usado para a </span>
<span class="co"># validação e o grau de liberdade utilizado</span>
fit_spline &lt;-<span class="st"> </span><span class="cf">function</span>(fold, freedom){
  
  <span class="co"># Erro de treinamento</span>
  d &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">filter</span>(ind <span class="op">!=</span><span class="st"> </span>fold)
  
  f &lt;-<span class="st"> </span><span class="kw">lm</span>(energy <span class="op">~</span><span class="st"> </span><span class="kw">ns</span>(danceability, freedom), 
          <span class="dt">data =</span> d) 
  rss_train &lt;-<span class="st"> </span><span class="kw">sum</span>((d<span class="op">$</span>energy <span class="op">-</span><span class="st"> </span>f<span class="op">$</span>fitted.values)<span class="op">^</span><span class="dv">2</span>)
  
  <span class="co"># Erro de validaçao</span>
  d &lt;-<span class="st"> </span>df <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">filter</span>(ind <span class="op">==</span><span class="st"> </span>fold)
  
  pred &lt;-<span class="st"> </span><span class="kw">predict</span>(f, <span class="dt">newdata =</span> d)
  
  rss_val &lt;-<span class="st"> </span><span class="kw">sum</span>((d<span class="op">$</span>energy <span class="op">-</span><span class="st"> </span>pred)<span class="op">^</span><span class="dv">2</span>)
  
  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">train =</span> rss_train, <span class="dt">val =</span> rss_val))
}

<span class="co"># Criando as combinações de folds e graus de liberdade</span>
cen &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">fold =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, <span class="dt">l =</span> <span class="dv">10</span><span class="op">:</span><span class="dv">35</span>)
n &lt;-<span class="st"> </span><span class="kw">nrow</span>(df)
k &lt;-<span class="st"> </span><span class="dv">5</span>
df<span class="op">$</span>ind &lt;-<span class="st"> </span><span class="kw">ceiling</span>((<span class="dv">1</span><span class="op">:</span>n)<span class="op">/</span>(n<span class="op">/</span>k))

<span class="co"># Aplicando os dois argumentos na função criada anteriormente</span>
res &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map2</span>(cen<span class="op">$</span>fold, cen<span class="op">$</span>l, <span class="dt">.f =</span> fit_spline)
cen &lt;-<span class="st"> </span>cen <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">val =</span> <span class="kw">unlist</span>(res <span class="op">%&gt;%</span><span class="st">  </span><span class="kw">map</span>(<span class="st">&quot;val&quot;</span>)),
                      <span class="dt">train =</span> <span class="kw">unlist</span>(res <span class="op">%&gt;%</span><span class="st">  </span><span class="kw">map</span>(<span class="st">&quot;train&quot;</span>)))



<span class="co"># Mostrando os resultados em gráficos</span>
p1 &lt;-<span class="st"> </span>cen <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(l, train)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> <span class="kw">factor</span>(fold))) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_colour_pomological</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">guides</span>(<span class="dt">colour =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Erro de treino&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;Graus de liberdade&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()

p2 &lt;-<span class="st"> </span>cen <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(l, val)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> <span class="kw">factor</span>(fold))) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_colour_pomological</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Fold&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Erro de validação&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;Graus de liberdade&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()

p1 <span class="op">+</span><span class="st"> </span>p2 <span class="op">+</span><span class="st"> </span><span class="kw">plot_layout</span>(<span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre>
<p><img src="bookdown_files/figure-html/unnamed-chunk-3-1.svg" width="672" style="display: block; margin: auto;" /></p>
<p>Neste caso, podemos ver que para os dados de treino, aumentar a quantidade
de graus de liberdade leva à uma melhoria crescente na previsão
das observações. Todavia, na amostra de validação o comportamento é diferente,
existindo um ponto aonde ter graus de liberdade demais passa a ser prejudicial,
pois aumenta o erro de previsão. Para estes dados, um valor bom para
os graus de liberdade pode ser encontrado com:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Encontrado o número de graus de liberdade que gerou o menor erro de </span>
<span class="co"># validação médio entre os 5 folds:</span>

cen <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(l) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">m =</span> <span class="kw">mean</span>(val)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(m) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)</code></pre>
<pre><code>FALSE # A tibble: 5 x 2
FALSE       l     m
FALSE   &lt;int&gt; &lt;dbl&gt;
FALSE 1    14 0.485
FALSE 2    13 0.500
FALSE 3    15 0.533
FALSE 4    10 0.535
FALSE 5    16 0.540</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">cen <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(l, val)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> <span class="kw">factor</span>(fold))) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_colour_pomological</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Fold&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">14</span>, <span class="dt">linetype =</span> <span class="st">&quot;dotted&quot;</span>, <span class="dt">size =</span> <span class="fl">1.4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Erro de validação&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;Graus de liberdade&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<p><img src="bookdown_files/figure-html/unnamed-chunk-4-1.svg" width="432" style="display: block; margin: auto;" /></p>
<p>Ou seja, 14 graus de liberdade levaram à menor taxa de erro durante o
processo de validação cruzada. Com isso, o método nos ajudou a encontrar
um bom valor para os graus de liberdade do modelo.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yihui/bookdown-crc/edit/master/01-validacao.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown.pdf", "bookdown.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
